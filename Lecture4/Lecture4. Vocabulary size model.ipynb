{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hidden-wellington",
   "metadata": {},
   "source": [
    "# 연구 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-russia",
   "metadata": {},
   "source": [
    "> 자연어 처리 분야에서 컴퓨터에게 언어를 효율으로 학습시키기 위해, 다양한 머신러닝 알고리듬이 연구되었고 기존 하드웨어 성능의 한계로 인한 문제가 개선됨에 따라 자연어를 딥러닝에 적용하는 연구도 활발하게 진행되고 있다. 이에, 본 연구에서는 Keras사에서 제공하는 '로이터 뉴스(Reuters News)' 데이터를 활용하여 머신러닝 알고리듬과 딥러닝 모델의 성능을 비교하고, 모델에서 사용하는 단어 수(vacabulary size)의 차이가 모델 성능에 영향을 미치는지 분석하는 실험을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "reasonable-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-devon",
   "metadata": {},
   "source": [
    "# 1. Reuters News Data EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-occasion",
   "metadata": {},
   "source": [
    "> 본 1장에서는 데이터 전처리 이전에 Reuters News 데이터의 특징을 분석하는 과정을 기술한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-advocacy",
   "metadata": {},
   "source": [
    "## 1.1 Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-equation",
   "metadata": {},
   "source": [
    "> Reuters News 데이터를 8:2 비율로 학습 데이터와 테스트 데이터로 분할하여 데이터를 메모리에 할당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "external-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coral-soldier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 text 개수: 8982\n",
      "학습 데이터 label 개수: 8982\n",
      "테스트 데이터 text 개수: 2246\n",
      "테스트 데이터 label 개수: 2246\n"
     ]
    }
   ],
   "source": [
    "print(f'학습 데이터 text 개수: {len(x_train)}')\n",
    "print(f'학습 데이터 label 개수: {len(y_train)}')\n",
    "print(f'테스트 데이터 text 개수: {len(x_test)}')\n",
    "print(f'테스트 데이터 label 개수: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-integer",
   "metadata": {},
   "source": [
    "> 학습 데이터는 8,982개, 테스트 데이터는 2246개이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-drinking",
   "metadata": {},
   "source": [
    "## 1.2 Data Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-asset",
   "metadata": {},
   "source": [
    "### 1.2.1 뉴스 주제 종류 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-blowing",
   "metadata": {},
   "source": [
    "> Reuters News는 뉴스 주제(카테고리)를 라벨에 분류하여 표기하였고, 이를 활용하여 카데고리의 개수를 분석한다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fatty-budget",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 주제(카테고리)의 종류 가지 수 : 46\n"
     ]
    }
   ],
   "source": [
    "set_lable = set(y_test)\n",
    "news_label = max(set_lable)+1\n",
    "\n",
    "print(f'뉴스 주제(카테고리)의 종류 가지 수 : {news_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-petite",
   "metadata": {},
   "source": [
    "> Reuters News는 46가지의 주제가 분포되어있음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-sponsorship",
   "metadata": {},
   "source": [
    "### 1.2.2 본문의 단어 종류 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-plasma",
   "metadata": {},
   "source": [
    "> 본문 텍스트의 종류 개수를 분석한 결과는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sexual-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuters News의 본문 개수 : 11228 개\n",
      "Reuters News의 단어 종류 개수 : 30980 가지\n"
     ]
    }
   ],
   "source": [
    "df_sentence = np.concatenate((x_train, x_test), axis=0)\n",
    "print(f\"Reuters News의 본문 개수 : {len(df_sentence)} 개\")\n",
    "\n",
    "df_text = set()\n",
    "for sentence in df_sentence:\n",
    "    df_text.update(sentence)\n",
    "    \n",
    "print(f\"Reuters News의 단어 종류 개수 : {len(df_text)} 가지\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-think",
   "metadata": {},
   "source": [
    "> 뉴스 본문은 11,228 개 이며, 본문에 사용된 단어의 종류는 30,980 가지이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-reset",
   "metadata": {},
   "source": [
    "## 1.3 Data Distribution analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-mozambique",
   "metadata": {},
   "source": [
    "> Reuters News의 본문과 주제의 구성를 분석하기 위한 분포도를 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-liabilities",
   "metadata": {},
   "source": [
    "### 1.3.1 뉴스 본문 데이터 분포도 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-arena",
   "metadata": {},
   "source": [
    "> Reuters News 본문 데이터의 분포를 분석하기위한 사용자 정의 함수를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nuclear-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distribution_data(df_data, title='데이터'):\n",
    "    print(f'{title}의 본문 최대 길이 :{max(len(l) for l in df_data)}')\n",
    "    print(f'{title}의 본문 평균 길이 :{sum(map(len, x_train))/len(x_train)}')\n",
    "\n",
    "    plt.hist([len(s) for s in df_data], bins=50)\n",
    "    plt.xlabel('length of samples')\n",
    "    plt.ylabel('number of samples')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-volunteer",
   "metadata": {},
   "source": [
    "> 학습 데이터의 뉴스 본문 분포도를 분석한 결과 가장 긴 뉴스 본문은 2,376자, 평균 145자이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expressed-difference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터의 본문 최대 길이 :2376\n",
      "학습 데이터의 본문 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZuUlEQVR4nO3df7RldXnf8ffHEdBGGoZAWMgPB3WSqI0SvCpZoSlqBcS0aGsU24QRiUQLEVu1GaIVNGUFmqipJiEOgThaI2VFDVOh4kggxvqDGXAEBkIYBcpMEEZRfmhEgad/7O+tx8u9s8/cmXPvufe+X2vtdfZ59o/z7MO587D3/u7vN1WFJEk78rj5TkCSNP4sFpKkXhYLSVIvi4UkqZfFQpLU6/HzncAo7LfffrVixYr5TkOSFpRrr732m1W1/3TLFmWxWLFiBRs3bpzvNCRpQUlyx0zLRnYZKskTklyT5KtJNid5V4sfluTLSbYk+Z9J9mzxvdr7LW35ioF9ndnityQ5dlQ5S5KmN8p7Fg8BL6qq5wCHA8clORI4D3hfVT0d+DZwSlv/FODbLf6+th5JngmcCDwLOA74kyTLRpi3JGmKkRWL6jzY3u7RpgJeBPxli68FXt7mT2jvactfnCQtfnFVPVRVtwFbgOePKm9J0mONtDVUkmVJNgH3AOuBrwHfqaqH2ypbgYPa/EHAnQBt+X3ATw3Gp9lm8LNOTbIxycbt27eP4GgkaekaabGoqkeq6nDgYLqzgZ8b4WetqaqJqprYf/9pb+ZLkmZpTp6zqKrvAFcBvwjsk2SyFdbBwLY2vw04BKAt/0ngW4PxabaRJM2BUbaG2j/JPm3+icBLgJvpisYr22qrgEvb/Lr2nrb8r6vrEncdcGJrLXUYsBK4ZlR5S5Iea5TPWRwIrG0tlx4HXFJVn0pyE3Bxkv8KfAW4sK1/IfCRJFuAe+laQFFVm5NcAtwEPAycVlWPjDBvSdIUWYzjWUxMTJQP5UnSzklybVVNTLdsUT7BPSorVl82bfz2c182x5lI0tyyI0FJUi+LhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUi+LhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUi+LhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUq+RFYskhyS5KslNSTYnOaPFz06yLcmmNh0/sM2ZSbYkuSXJsQPx41psS5LVo8pZkjS9x49w3w8Db6mq65LsDVybZH1b9r6q+oPBlZM8EzgReBbwZOCzSX6mLf5j4CXAVmBDknVVddMIc5ckDRhZsaiqu4C72vwDSW4GDtrBJicAF1fVQ8BtSbYAz2/LtlTV1wGSXNzWtVhI0hyZk3sWSVYAvwB8uYVOT3J9kouSLG+xg4A7Bzbb2mIzxad+xqlJNibZuH379t19CJK0pI28WCR5EvBx4M1VdT9wPvA04HC6M4/37I7Pqao1VTVRVRP777//7tilJKkZ5T0LkuxBVyg+WlWfAKiquweWXwB8qr3dBhwysPnBLcYO4pKkOTDK1lABLgRurqr3DsQPHFjtFcCNbX4dcGKSvZIcBqwErgE2ACuTHJZkT7qb4OtGlbck6bFGeWbxS8CvAzck2dRivwO8JsnhQAG3A78JUFWbk1xCd+P6YeC0qnoEIMnpwBXAMuCiqto8wrwlSVOMsjXU54FMs+jyHWxzDnDONPHLd7SdJGm0fIJbktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUi+LhSSpl8VCktRrpB0JLlQrVl823ylI0ljxzEKS1MtiIUnqZbGQJPWyWEiSelksJEm9LBaSpF4WC0lSr95ikeRXk+zd5t+R5BNJjhh9apKkcTHMmcV/qaoHkhwF/EvgQuD80aYlSRonwxSLR9rry4A1VXUZsOfoUpIkjZthisW2JB8EXg1cnmSvIbeTJC0Sw/yj/yrgCuDYqvoOsC/wtlEmJUkaL73Foqq+B9wDHNVCDwO3jjIpSdJ4GaY11FnAbwNnttAewP8YZVKSpPEyzGWoVwD/GvguQFX9A7D3KJOSJI2XYYrFD6qqgAJI8hOjTUmSNG6GKRaXtNZQ+yR5PfBZ4ILRpiVJGifD3OD+A+AvgY8DPwu8s6o+0LddkkOSXJXkpiSbk5zR4vsmWZ/k1va6vMWT5P1JtiS5fvAp8SSr2vq3Jlk124OVJM3OUMOqVtV6YP1O7vth4C1VdV3rLuTaJOuB1wJXVtW5SVYDq+luoL8UWNmmF9A9Jf6CJPsCZwETdJfCrk2yrqq+vZP5SJJmacYziyQPJLl/mumBJPf37biq7qqq69r8A8DNwEHACcDattpa4OVt/gTgw9X5Et1lrwOBY4H1VXVvKxDrgeNmd7iSpNmY8cyiqnZbi6ckK4BfAL4MHFBVd7VF3wAOaPMHAXcObLa1xWaKT/2MU4FTAQ499NDdlbokiSEvQ7X7B0fRXQb6fFV9ZdgPSPIkuvsdb66q+5P8/2VVVUlq51KeXlWtAdYATExM7JZ9SpI6wzyU9066y0U/BewHfCjJO4bZeZI96ArFR6vqEy18d7u8RHu9p8W3AYcMbH5wi80UlyTNkWGazv574HlVdVZVnQUcCfx630bpTiEuBG6uqvcOLFoHTLZoWgVcOhA/qbWKOhK4r12uugI4Jsny1nLqmBaTJM2RYS5D/QPwBOD77f1eDPd/9r9EV1RuSLKpxX4HOJfu2Y1TgDvoOioEuBw4HtgCfA84GaCq7k3yu8CGtt67q+reIT5fkrSbDFMs7gM2t2avBbwEuCbJ+wGq6k3TbVRVnwcy3TLgxdOsX8BpM+zrIuCiIXKVJI3AMMXik22adPVoUpEkjaveYlFVa/vWkSQtbsO0hvqVJF9Jcu/OPJQnSVo8hrkM9YfAvwFuaPcVJElLzDBNZ+8EbrRQSNLSNcyZxX8GLk/yN8BDk8Epz05IkhaxYYrFOcCDdM9a7DnadCRJ42iYYvHkqvpnI89EkjS2hrlncXmSY0aeiSRpbA1TLN4IfDrJP9p0VpKWpmEeyttt41pIkhamYcezWE433OkTJmNV9blRJSVJGi+9xSLJbwBn0I0jsYmui/IvAi8aaWaSpLExzD2LM4DnAXdU1Qvphkf9ziiTkiSNl2GKxfer6vsASfaqqr8Dfna0aUmSxskw9yy2JtkH+CtgfZJv0w1aJElaIoZpDfWKNnt2kquAnwQ+PdKsJEljZZguyp+WZK/Jt8AK4J+MMilJ0ngZ5p7Fx4FHkjwdWAMcAvzFSLOSJI2VYYrFo1X1MPAK4ANV9TbgwNGmJUkaJ8MUix8meQ2wCvhUi+0xupQkSeNmmGJxMvCLwDlVdVuSw4CPjDYtSdI4GaY11E3Amwbe3wacN8qkJEnjZZgzC0nSEmexkCT1mrFYJPlIez1j7tKRJI2jHZ1ZPDfJk4HXJVmeZN/BqW/HSS5Kck+SGwdiZyfZlmRTm44fWHZmki1Jbkly7ED8uBbbkmT1bA9UkjR7O7rB/afAlcBTgWvpnt6eVC2+Ix8C/gj48JT4+6rqDwYDSZ4JnAg8C3gy8NkkP9MW/zHwEmArsCHJunbTXZI0R2Y8s6iq91fVM4CLquqpVXXYwNRXKCYHR7p3yDxOAC6uqodaa6stwPPbtKWqvl5VPwAubutKkuZQ7w3uqnpjkuckOb1Nz97Fzzw9yfXtMtXyFjsIuHNgna0tNlP8MZKcmmRjko3bt2/fxRQlSYOG6UjwTcBHgZ9u00eT/NYsP+984GnA4cBdwHtmuZ/HqKo1VTVRVRP777//7tqtJInhxrP4DeAFVfVdgCTn0Q2r+oGd/bCquntyPskF/Kj7kG10HRROOrjF2EFckjRHhnnOIsAjA+8f4cdvdg8tyWAHhK8AJltKrQNOTLJX605kJXANsAFYmeSwJHvS3QRfN5vPliTN3jBnFn8OfDnJJ9v7lwMX9m2U5GPA0cB+SbYCZwFHJzmcrjXV7cBvAlTV5iSXADcBDwOnVdUjbT+nA1cAy+hutm8e8tgkSbvJMH1DvTfJ1cBRLXRyVX1liO1eM014xiJTVecA50wTvxy4vO/zJEmjM8yZBVV1HXDdiHORJI0p+4aSJPWyWEiSeu2wWCRZluSquUpGkjSedlgsWoukR5P85BzlI0kaQ8Pc4H4QuCHJeuC7k8GqetPMm0iSFpNhisUn2iRJWqKGec5ibZInAodW1S1zkJMkacwM05HgvwI2AZ9u7w9PYpcbkrSEDNN09my6cSW+A1BVm+gf+EiStIgMUyx+WFX3TYk9OopkJEnjaZgb3JuT/DtgWZKVwJuAL4w2LUnSOBnmzOK36MbGfgj4GHA/8OYR5iRJGjPDtIb6HvD2NuhRVdUDo09LkjROhmkN9bwkNwDX0z2c99Ukzx19apKkcTHMPYsLgf9QVX8LkOQougGRnj3KxCRJ42OYexaPTBYKgKr6PN1odpKkJWLGM4skR7TZv0nyQbqb2wW8Grh69KlJksbFji5DvWfK+7MG5msEuUiSxtSMxaKqXjiXiUiSxlfvDe4k+wAnASsG17eLcklaOoZpDXU58CXgBuzmQ5KWpGGKxROq6j+NPBNJ0tgaplh8JMnrgU/RdfkBQFXdO7KsFpgVqy+bNn77uS+b40wkaTSGKRY/AH4feDs/agVV2E25JC0ZwxSLtwBPr6pvjjoZSdJ4GuYJ7i3A90adiCRpfA1TLL4LbErywSTvn5z6NkpyUZJ7ktw4ENs3yfokt7bX5S2ett8tSa4feHqcJKva+rcmWTWbg5Qk7ZphisVfAefQDXh07cDU50PAcVNiq4Erq2olcGV7D/BSYGWbTgXOh6640D05/gK6oV3PmiwwkqS5M8x4Fmtns+Oq+lySFVPCJwBHt/m1dH1M/XaLf7iqCvhSkn2SHNjWXT/Z8irJeroC9LHZ5CRJmp1hnuC+jWn6gqqq2bSGOqCq7mrz3wAOaPMHAXcOrLe1xWaKT5fnqXRnJRx66KGzSE2SNJNhWkNNDMw/AfhVYN9d/eCqqiS7rUPCqloDrAGYmJiwo0NJ2o1671lU1bcGpm1V9YfAbJ82u7tdXqK93tPi24BDBtY7uMVmikuS5tAww6oeMTBNJHkDw52RTGcdMNmiaRVw6UD8pNYq6kjgvna56grgmCTL243tY1pMkjSHhvlHf3Bci4eB24FX9W2U5GN0N6j3S7KVrlXTucAlSU4B7hjYz+XA8fzomY6ToetSJMnvAhvaeu+2mxFJmnvDtIaa1bgWVfWaGRa9eJp1Czhthv1cBFw0mxwkSbvHMK2h9gL+LY8dz+Ldo0tLkjROhrkMdSlwH92DeA/1rCtJWoSGKRYHV9XUJ7ElSUvIMN19fCHJz488E0nS2BrmzOIo4LXtSe6HgNDdk372SDOTJI2NYYrFS0eehSRprA3TdPaOuUhkMXK4VUmLxTD3LCRJS5zFQpLUy2IhSeplsZAk9bJYSJJ6WSwkSb0sFpKkXhYLSVIvi4UkqZfFQpLUy2IhSeplsZAk9bJYSJJ6WSwkSb0sFpKkXhYLSVIvi4UkqZfFQpLUy2IhSeo1L8Uiye1JbkiyKcnGFts3yfokt7bX5S2eJO9PsiXJ9UmOmI+cJWkpm88zixdW1eFVNdHerwaurKqVwJXtPcBLgZVtOhU4f84zlaQlbpwuQ50ArG3za4GXD8Q/XJ0vAfskOXAe8pOkJWu+ikUBn0lybZJTW+yAqrqrzX8DOKDNHwTcObDt1hb7MUlOTbIxycbt27ePKm9JWpIeP0+fe1RVbUvy08D6JH83uLCqKkntzA6rag2wBmBiYmKntp1rK1ZfNm389nNfNseZSNJw5uXMoqq2tdd7gE8Czwfunry81F7vaatvAw4Z2PzgFpMkzZE5LxZJfiLJ3pPzwDHAjcA6YFVbbRVwaZtfB5zUWkUdCdw3cLlKkjQH5uMy1AHAJ5NMfv5fVNWnk2wALklyCnAH8Kq2/uXA8cAW4HvAyXOfsiQtbXNeLKrq68Bzpol/C3jxNPECTpuD1CRJMxinprOSpDFlsZAk9bJYSJJ6WSwkSb0sFpKkXhYLSVKv+eruQ9OwGxBJ48ozC0lSL4uFJKmXxUKS1MtiIUnqZbGQJPWyNdQCYCspSfPNMwtJUi+LhSSpl8VCktTLYiFJ6mWxkCT1sjXUAmYrKUlzxTMLSVIvi4UkqZeXoZaQmS5bgZeuJO2YxWIR2lFRkKTZ8DKUJKmXZxYCbFklaccsFpoVi4u0tFgstEO76/6HxUVa2BZMsUhyHPDfgWXAn1XVufOckqbhzXVpcVoQxSLJMuCPgZcAW4ENSdZV1U3zm5l21c4WF89EpPmxIIoF8HxgS1V9HSDJxcAJgMViibG4SPNjoRSLg4A7B95vBV4wuEKSU4FT29sHk9wyi8/ZD/jmrDJcHBbd8ee8nd5k0X0HO2mpHz8s7e/gKTMtWCjFoldVrQHW7Mo+kmysqondlNKCs9SPH/wOlvrxg9/BTBbKQ3nbgEMG3h/cYpKkObBQisUGYGWSw5LsCZwIrJvnnCRpyVgQl6Gq6uEkpwNX0DWdvaiqNo/go3bpMtYisNSPH/wOlvrxg9/BtFJV852DJGnMLZTLUJKkeWSxkCT1sljQdSWS5JYkW5Ksnu98RinJ7UluSLIpycYW2zfJ+iS3ttflLZ4k72/fy/VJjpjf7HdekouS3JPkxoHYTh9vklVt/VuTrJqPY5mtGb6Ds5Nsa7+DTUmOH1h2ZvsObkly7EB8Qf6dJDkkyVVJbkqyOckZLb6kfge7rKqW9ER3w/xrwFOBPYGvAs+c77xGeLy3A/tNif03YHWbXw2c1+aPB/43EOBI4Mvznf8sjveXgSOAG2d7vMC+wNfb6/I2v3y+j20Xv4OzgbdOs+4z29/AXsBh7W9j2UL+OwEOBI5o83sDf9+Oc0n9DnZ18sxioCuRqvoBMNmVyFJyArC2za8FXj4Q/3B1vgTsk+TAechv1qrqc8C9U8I7e7zHAuur6t6q+jawHjhu5MnvJjN8BzM5Abi4qh6qqtuALXR/Iwv276Sq7qqq69r8A8DNdL1CLKnfwa6yWEzflchB85TLXCjgM0mubV2kABxQVXe1+W8AB7T5xfrd7OzxLtbv4fR2meWiyUswLPLvIMkK4BeAL+PvYKdYLJaeo6rqCOClwGlJfnlwYXXn20umPfVSO94B5wNPAw4H7gLeM6/ZzIEkTwI+Dry5qu4fXLaEfwdDs1gssa5Eqmpbe70H+CTd5YW7Jy8vtdd72uqL9bvZ2eNddN9DVd1dVY9U1aPABXS/A1ik30GSPegKxUer6hMtvOR/BzvDYrGEuhJJ8hNJ9p6cB44BbqQ73smWHauAS9v8OuCk1jrkSOC+gdP2hWxnj/cK4Jgky9vlmmNabMGacu/pFXS/A+i+gxOT7JXkMGAlcA0L+O8kSYALgZur6r0Di5b872CnzPcd9nGY6Fo//D1da4+3z3c+IzzOp9K1YvkqsHnyWIGfAq4EbgU+C+zb4qEbdOprwA3AxHwfwyyO+WN0l1l+SHeN+ZTZHC/wOrqbvVuAk+f7uHbDd/CRdozX0/3jeODA+m9v38EtwEsH4gvy7wQ4iu4S0/XApjYdv9R+B7s62d2HJKmXl6EkSb0sFpKkXhYLSVIvi4UkqZfFQpLUy2KhBS/JgyPY5+FTemI9O8lbd2F/v5rk5iRX7Z4MZ53H7Un2m88ctDBZLKTpHU7XFn93OQV4fVW9cDfuU5ozFgstKknelmRD6yDvXS22ov1f/QVtPIPPJHliW/a8tu6mJL+f5Mb2hPK7gVe3+Kvb7p+Z5OokX0/yphk+/zXpxgu5Mcl5LfZOugfDLkzy+1PWPzDJ59rn3Jjkn7f4+Uk2tnzfNbD+7Ul+r62/MckRSa5I8rUkb2jrHN32eVm68Sf+NMlj/taT/FqSa9q+PphkWZs+1HK5Icl/3MX/JFos5vupQCenXZ2AB9vrMcAauidwHwd8im4shxXAw8Dhbb1LgF9r8zcCv9jmz6WN+QC8Fvijgc84G/gC3TgP+wHfAvaYkseTgf8L7A88Hvhr4OVt2dVM8wQ88BZ+9CT9MmDvNr/vQOxq4Nnt/e3AG9v8++ieSt67febdLX408H26J/aX0XWl/cqB7fcDngH8r8ljAP4EOAl4Ll033JP57TPf/32dxmPyzEKLyTFt+gpwHfBzdH0bAdxWVZva/LXAiiT70P3j/MUW/4ue/V9W3TgP36TrdO6AKcufB1xdVdur6mHgo3TFakc2ACcnORv4+erGWwB4VZLr2rE8i26wnkmTfTLdQDcwzwNVtR14qB0TwDXVjT3xCF13H0dN+dwX0xWGDUk2tfdPpRvQ56lJPpDkOOB+JLr/+5EWiwC/V1Uf/LFgN4bBQwOhR4AnzmL/U/exy38/VfW51k38y4APJXkv8LfAW4HnVdW3k3wIeMI0eTw6JadHB3Ka2o/P1PcB1lbVmVNzSvIcuoF+3gC8iq4/JC1xnlloMbkCeF0bt4AkByX56ZlWrqrvAA8keUELnTiw+AG6yzs74xrgXyTZL8ky4DXA3+xogyRPobt8dAHwZ3TDn/5T4LvAfUkOoBt7ZGc9v/UQ+zjg1cDnpyy/Enjl5PeTbjzqp7SWUo+rqo8D72j5SJ5ZaPGoqs8keQbwxa5Xah4Efo3uLGAmpwAXJHmU7h/2+1r8KmB1u0Tze0N+/l1JVrdtQ3fZ6tKezY4G3pbkhy3fk6rqtiRfAf6ObmS2/zPM50+xAfgj4Oktn09OyfWmJO+gGzXxcXQ90p4G/CPw5wM3xB9z5qGlyV5ntaQleVJVPdjmV9N11X3GPKe1S5IcDby1qn5lnlPRIuKZhZa6lyU5k+5v4Q66VlCSpvDMQpLUyxvckqReFgtJUi+LhSSpl8VCktTLYiFJ6vX/AHunIAk82uh/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_distribution_data(x_train, '학습 데이터')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-memory",
   "metadata": {},
   "source": [
    "> 테스트 데이터의 뉴스 본문 분포도를 분석한 결과 가장 긴 뉴스 본문은 1,032자, 평균 145자이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "structured-theater",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 본문 최대 길이 :1032\n",
      "테스트 데이터의 본문 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_distribution_data(x_test, '테스트 데이터')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-salem",
   "metadata": {},
   "source": [
    "### 1.3.2 뉴스 주제 데이터 분포도 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-census",
   "metadata": {},
   "source": [
    "> Reuters News 데이터의 주제(카테고리) 분포를 분석하기위한 사용자 정의 함수를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "driving-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distribution_category(df_data):\n",
    "    fig, axe = plt.subplots(ncols=1)\n",
    "    fig.set_size_inches(11,5)\n",
    "    sns.countplot(x=df_data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-adolescent",
   "metadata": {},
   "source": [
    "> 학습 데이터의 뉴스 주제 분포도를 분석한 결과 가장 높은 빈도는 '3'이고, 이어서 '4', '19', '16', '1' 순으로 빈도가 높았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "genetic-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>432</td>\n",
       "      <td>74</td>\n",
       "      <td>3159</td>\n",
       "      <td>1949</td>\n",
       "      <td>17</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>139</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2     3     4   5   6   7    8    9   ...  36  37  38  39  40  41  \\\n",
       "0   0    1   2     3     4   5   6   7    8    9  ...  36  37  38  39  40  41   \n",
       "1  55  432  74  3159  1949  17  48  16  139  101  ...  49  19  19  24  36  30   \n",
       "\n",
       "   42  43  44  45  \n",
       "0  42  43  44  45  \n",
       "1  13  21  12  18  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "display(pd.DataFrame(np.asarray((unique_elements, counts_elements))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dangerous-heaven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_distribution_category(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-nicholas",
   "metadata": {},
   "source": [
    "> 테스트 데이터의 뉴스 주제 분포도를 분석한 결과, 학습 데이터의 분포도와 동일한 비율의 결과를 보여주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "elect-affect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>105</td>\n",
       "      <td>20</td>\n",
       "      <td>813</td>\n",
       "      <td>474</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2    3    4   5   6   7   8   9   ...  36  37  38  39  40  41  42  \\\n",
       "0   0    1   2    3    4   5   6   7   8   9  ...  36  37  38  39  40  41  42   \n",
       "1  12  105  20  813  474   5  14   3  38  25  ...  11   2   3   5  10   8   3   \n",
       "\n",
       "   43  44  45  \n",
       "0  43  44  45  \n",
       "1   6   5   1  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_test, return_counts=True)\n",
    "display(pd.DataFrame(np.asarray((unique_elements, counts_elements))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expressed-antarctica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_distribution_category(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-boston",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-apache",
   "metadata": {},
   "source": [
    "> 본 2 장에서는 자연어 처리 모델에 활용할 단어장을 생성하는 과정을 기술한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-particle",
   "metadata": {},
   "source": [
    "## 2.1 단어장 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-architecture",
   "metadata": {},
   "source": [
    "> Keras사에서 제공하는 '로이터 뉴스(Reuters News)' library의 word to index.json을 활용하여 Vocabulary를 생성한다.<br>\n",
    "> Reuters News의 word2index의 index는 +3을 했을때 고유 번호이므로, 1번 인덱스를 4번으로 옮기는 작업을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "finnish-grenada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 30979\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "index_to_word = {index+3 : word for word, index in word_index.items()}\n",
    "print(\"vocabulary size:\", len(index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-organization",
   "metadata": {},
   "source": [
    "> 위 작업으로 사용되지 않는 0~2번 index에 pad, sos, unk 토큰을 추가하여, 단어장의 총 크기는 30,982이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "recognized-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 30982\n"
     ]
    }
   ],
   "source": [
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "print(\"vocabulary size:\", len(index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-audit",
   "metadata": {},
   "source": [
    "## 2.2 단어장을 활용한 문장 복원 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-intellectual",
   "metadata": {},
   "source": [
    "> 위 2.1장에서 구성한 vocabulary를 활용하여 학습 데이터와 테스트 데이터의 문장을 복원하는 실험을 위한 사용자 정의 함수를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "infinite-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_index_to_word(df_data):\n",
    "    decoded = []\n",
    "    for i in range(len(df_data)):\n",
    "        decoded += [' '.join([index_to_word[index] for index in df_data[i]])]\n",
    "        \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-export",
   "metadata": {},
   "source": [
    "> 학습 데이터의 정수형 시퀀스 데이터를 문자형 데이터로 복원하였을때 결과는 아래와 같다.<br>\n",
    "> 단어장에 등록되지 않은 단어는 정수형 데이터로 표현함을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "choice-innocent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<sos> currency fluctuations may reassert their influence on the bullion market in the near future bullion bankers samuel montagu and co ltd said in a market report but the firm said silver may lag behind gold in any reactions to movements on foreign exchanges opec's failure to address the recent decline in oil prices remains a worrying factor however and on balance it appears that the market should be approached cautiously montagu said the bank said the us economy has shown no noticeable long term improvement and that both latin american debt and the iranian arms affair could undermine confidence in the dollar reuter 3\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = decode_index_to_word(x_train)\n",
    "train_data[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-control",
   "metadata": {},
   "source": [
    "> 테스트 데이터의 정수형 시퀀스 데이터를 문자형 데이터로 복원하였을때 결과는 아래와 같다.<br>\n",
    "> 단어장에 등록되지 않은 일부 단어는 정수형 데이터로 표현함을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "competitive-worst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<sos> congress should give the u s agriculture secretary the authority to keep the 1987 soybean loan rate at the current effective rate of 4 56 dlrs per bushel in order to help resolve the problem of soybean export competitiveness usda undersecretary dan amstutz said speaking to reporters following a senate agriculture appropriations hearing amstutz suggested that one way out of the current soybean program dilemma would be for congress to allow the loan rate to remain at 4 56 dlrs he indicated if the loan rate were 4 56 dlrs usda could then consider ways to make u s soybeans more competitive such as using certificates to further buydown the loan rate under current law the 1987 soybean loan rate cannot be less than 4 77 dlrs per bu amstutz' suggestion would be for congress to change the farm bill to allow usda to leave the soybean loan rate at 4 56 dlrs in crop year 1987 rather than increase it to 4 77 dlrs the 1986 effective loan rate is 4 56 dlrs because of the 4 3 pct gramm rudman budget cut amstutz stressed that a major factor in any decision on soybean program changes will be the budget costs he told the hearing that the problem in soybeans is that the u s loan rate provides an umbrella to foreign production and causes competitive problems for u s soybeans asked about the american soybean association's request for some form of income support amstutz said the competitive problem is the most severe he said usda is still studying the situation and no resolution has yet been found reuter 3\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = decode_index_to_word(x_test)\n",
    "test_data[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-prison",
   "metadata": {},
   "source": [
    "## 2.3 TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-occasion",
   "metadata": {},
   "source": [
    "> 뉴스 본문 데이터를 텍스트 분류 모델의 입력 데이터로 활용하려면 각 본문을 벡터화할 필요가 있다.<br>\n",
    "> 이에, 뉴스 본문을 서로 다른 문서들의 Bag of Words을 결합한 DTM(Document-Term Matrix)으로 변환 하고,<br>\n",
    "> DTM의 희소 표현과 단순 빈도 수 기반 접근의 한계점을 개선한 TF-IDF으로 변환하는 사용자 정의 함수를 구현한다.<br>\n",
    "> TF-IDF(Term Frequency-Inverse Document Frequency)는 DTM 내의 각 단어마다 중요한 정도의 가중치를 구하는 방법이다.<br>\n",
    "> 이는 문서의 빈도에 특정 식을 취함으로써, DTM을 사용하는 것보다 보다 더 많은 정보를 고려하여 문서들을 비교할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cubic-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TFIDF(train_data, test_data):  \n",
    "    # step1. DTM, TF-IDF 객체 생성\n",
    "    dtmvector = CountVectorizer()\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    \n",
    "    # step2. array -> DTM matrix convert\n",
    "    train_data = dtmvector.fit_transform(train_data)\n",
    "    test_data = dtmvector.transform(test_data)\n",
    "    \n",
    "    # step3. DTM -> TF-IDF matrix convert\n",
    "    train_data = tfidf_transformer.fit_transform(train_data)\n",
    "    test_data = tfidf_transformer.transform(test_data)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-coordinate",
   "metadata": {},
   "source": [
    "## 2.4 사용 단어 개수가 다른 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-advertising",
   "metadata": {},
   "source": [
    "> 본 연구의 목표중 하나인 모델에서 사용하는 단어 수(vacabulary size)의 차이가 모델에 어떤 영향을 미치는지를 분석하고자 한다.<br>\n",
    "> 이에, 아래의 조건을 만족하는 후보군 3개를 8:2 비율로 학습 데이터와 테스트 데이터를 구성하고<br>\n",
    "> 모델 입력 데이터로 활용할 수 있도록 각 후보군에 2.2~ 2.3장의 전처리를 수행한다.<br>\n",
    "> <br>\n",
    "> 1. normal_data : 모든 단어(약 30,000개)를 사용하여 구성된 데이터.<br>\n",
    "> 2. word_5000_data : 사용빈도가 5,000위 이내인 단어로만 구성된 데이터.<br>\n",
    "> 3. word_15000_data : 사용빈도가 15,000위 이내인 단어로만 구성된 데이터.(normal 후보군 대비 1/2)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-sport",
   "metadata": {},
   "source": [
    "### 2.4.1 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ongoing-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(normal_x_train, normal_y_train), (normal_x_test, normal_y_test) = reuters.load_data(test_split=0.2)\n",
    "(word_5000_x_train, word_5000_y_train), (word_5000_x_test, word_5000_y_test) = reuters.load_data(num_words=5000, test_split=0.2)\n",
    "(word_15000_x_train, word_15000_y_train), (word_15000_x_test, word_15000_y_test) = reuters.load_data(num_words=15000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-harassment",
   "metadata": {},
   "source": [
    "### 2.4.2 Integer sequence data decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "scenic-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_normal_x_train = decode_index_to_word(normal_x_train)\n",
    "d_normal_x_test = decode_index_to_word(normal_x_test)\n",
    "\n",
    "d_word_5000_x_train = decode_index_to_word(word_5000_x_train)\n",
    "d_word_5000_x_test = decode_index_to_word(word_5000_x_test)\n",
    "\n",
    "d_word_15000_x_train = decode_index_to_word(word_15000_x_train)\n",
    "d_word_15000_x_test = decode_index_to_word(word_15000_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-basin",
   "metadata": {},
   "source": [
    "### 2.4.3 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "settled-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_x_train, normal_x_test = get_TFIDF(d_normal_x_train, d_normal_x_test)\n",
    "word_5000_x_train, word_5000_x_test = get_TFIDF(d_word_5000_x_train, d_word_5000_x_test)\n",
    "word_15000_x_train, word_15000_x_test = get_TFIDF(d_word_15000_x_train, d_word_15000_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-peace",
   "metadata": {},
   "source": [
    "# 3. 각 모델 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-purpose",
   "metadata": {},
   "source": [
    "> 본 3장에서는 3가지 단어장 후보군을 여러 종류의 머신러닝 모델과 LSTM 딥러닝 모델에 학습한 결과를 기술한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-girlfriend",
   "metadata": {},
   "source": [
    "## 3.1 Create Utility Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-links",
   "metadata": {},
   "source": [
    "> 다수의 모델을 편리하게 사용하기 위한 모델 학습 후, 결과를 출력하는 사용자 정의 함수를 구현한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "overhead-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_test(x_train, y_train, x_test, y_test, model, sentence):\n",
    "    model.fit(x_train, y_train)\n",
    "    model_predict = model.predict(x_test)\n",
    "    \n",
    "    #print(classification_report(y_test, model_predict))\n",
    "    print('-'*40)\n",
    "    print(f'\\t{sentence}')\n",
    "    print('-'*40)\n",
    "    print(f'정확도 :  {round(accuracy_score(y_test, model_predict),4)}')\n",
    "    print(f'F1-Score의 macro 평균 :  {round(f1_score(y_test, model_predict, average=\"macro\"),4)}')\n",
    "    print(f'F1-Score의 micro 평균 :  {round(f1_score(y_test, model_predict, average=\"micro\"),4)}')\n",
    "    print(f'F1-Score의 weight 평균 :  {round(f1_score(y_test, model_predict, average=\"weighted\"),4)}')\n",
    "    print('-'*40,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-cooperation",
   "metadata": {},
   "source": [
    "## 3.2 머신러닝 알고리듬 기반 모델 학습&테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-representative",
   "metadata": {},
   "source": [
    "> 연구에 사용되는 머신러닝 모델은 아래와 같다.<br>\n",
    "> <br>\n",
    "> 1. 나이브 베이즈 분류기(Multinomial Naive Bayes Classifier)<br>\n",
    "> 2. 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier)<br>\n",
    "> 3. 로지스틱 회귀(Logistic Regression)<br>\n",
    "> 4. 선형 서포트 벡터 머신(Linear Support Vector Machine)<br>\n",
    "> 5. 결정 트리(Decision Tree)<br>\n",
    "> 6. 랜덤 포레스트(Random Forest)<br>\n",
    "> 7. 그래디언트 부스팅 트리(GradientBoostingClassifier)<br>\n",
    "> 8. 보팅(Voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-intensity",
   "metadata": {},
   "source": [
    "### 3.2.1 나이브 베이즈 분류기(Multinomial Naive Bayes Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-granny",
   "metadata": {},
   "source": [
    "> 나이브 베이즈 분류기는 텍스트 분류를 위해 전통적으로 사용되는 분류기로 머신 러닝의 주요 알고리즘으로 분류에 있어 준수한 성능을 보여주는 것으로 알려져 있다.<br>\n",
    "> <br>\n",
    "> 나이브 베이즈 분류기는 조건부 확률을 계산하는 방법인 ['베이즈 정리'](https://ko.wikipedia.org/wiki/%EB%B2%A0%EC%9D%B4%EC%A6%88_%EC%A0%95%EB%A6%AC)를 이용하여 텍스트 분류를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "roman-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\t전체 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.5997\n",
      "F1-Score의 macro 평균 :  0.0677\n",
      "F1-Score의 micro 평균 :  0.5997\n",
      "F1-Score의 weight 평균 :  0.5046\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t5,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.6732\n",
      "F1-Score의 macro 평균 :  0.1102\n",
      "F1-Score의 micro 평균 :  0.6732\n",
      "F1-Score의 weight 평균 :  0.6013\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t15,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.6331\n",
      "F1-Score의 macro 평균 :  0.0853\n",
      "F1-Score의 micro 평균 :  0.6331\n",
      "F1-Score의 weight 평균 :  0.5498\n",
      "---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_train_test(normal_x_train, normal_y_train, normal_x_test, normal_y_test, MultinomialNB(),'전체 단어장')\n",
    "model_train_test(word_5000_x_train, word_5000_y_train, word_5000_x_test, word_5000_y_test, MultinomialNB(),'5,000 단어장')\n",
    "model_train_test(word_15000_x_train, word_15000_y_train, word_15000_x_test, word_15000_y_test, MultinomialNB(),'15,000 단어장')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-potential",
   "metadata": {},
   "source": [
    "> 나이브 베이즈 분류기의 정확도는 5,000 단어장(67.32%), 15,000 단어장(63.31%), 모든 단어장(59.97%)이다.<br>\n",
    "> 단어장의 크기가 클수록 낮은 정확도를 기록하는 모습을 보여준다.<br>\n",
    "> 이는 해당 모델이 독립 변수가 '조건부로 독립적'이라는 가정으로 연산하기에 단어장의 크기가 클수록 특정 단어에 편향되는 것으로 생각된다.<br>\n",
    "> <br>\n",
    "> F1-Score의 weight는 5,000 단어장(0.6013), 15,000 단어장(0.5498), 모든 단어장(0.5046)의 결과를 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-indiana",
   "metadata": {},
   "source": [
    "### 3.2.2 컴플리먼트 나이브 베이즈 분류기(Complement Naive Bayes Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-entity",
   "metadata": {},
   "source": [
    "> 컴플리먼트 나이브 베이즈 분류기는 데이터가 불균형한 정도에 따라, 가중치를 부여하는 모델이다.<br>\n",
    "> 이는, 기존 나이브 베이즈 분류기에서 데이터가 불균형할 때, 가중치가 편향되는 단점을 개선했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "allied-population",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\t전체 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.7649\n",
      "F1-Score의 macro 평균 :  0.464\n",
      "F1-Score의 micro 평균 :  0.7649\n",
      "F1-Score의 weight 평균 :  0.7347\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t5,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.7707\n",
      "F1-Score의 macro 평균 :  0.482\n",
      "F1-Score의 micro 평균 :  0.7707\n",
      "F1-Score의 weight 평균 :  0.7459\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t15,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.772\n",
      "F1-Score의 macro 평균 :  0.4668\n",
      "F1-Score의 micro 평균 :  0.772\n",
      "F1-Score의 weight 평균 :  0.7448\n",
      "---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_train_test(normal_x_train, normal_y_train, normal_x_test, normal_y_test, ComplementNB(),'전체 단어장')\n",
    "model_train_test(word_5000_x_train, word_5000_y_train, word_5000_x_test, word_5000_y_test, ComplementNB(),'5,000 단어장')\n",
    "model_train_test(word_15000_x_train, word_15000_y_train, word_15000_x_test, word_15000_y_test, ComplementNB(),'15,000 단어장')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-norway",
   "metadata": {},
   "source": [
    "> 컴플리먼트 나이브 베이즈 분류기의 정확도는 5,000 단어장(77.07%), 15,000 단어장(77.2%), 모든 단어장(76.49%)이다.<br>\n",
    "> 이전 나이브 베이즈 분류기모델에 비해 단어장의 크기에 영향을 적게 받는 모습을 보여준다.<br>\n",
    "> 따라서, 불균형한 데이터에서 효율적인 모델임 알 수 있다.<br>\n",
    "> <br>\n",
    "> F1-Score의 weight는 5,000 단어장(0.7459), 15,000 단어장(0.7448), 모든 단어장(0.7347)의 결과를 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-characteristic",
   "metadata": {},
   "source": [
    "### 3.2.3 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-order",
   "metadata": {},
   "source": [
    "> 로지스틱 회귀는 선형 분류 알고리듬으로, 소프트맥스(softmax) 함수를 활용한 다중 클래스 분류에 강점을 보이는 모델이다.<br>\n",
    "> 로지스틱 '회귀'의 이름때문에, 실제 값을 유추하는 회귀 기능을 수행할 것이라는 착각에 빠지기 쉽다.<br>\n",
    "> 로지스틱 회귀가 소프트맥스 함수를 사용하기에, 클래스를 확률로 '분류'하는 기능을 수행함을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "atomic-bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\t전체 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.817\n",
      "F1-Score의 macro 평균 :  0.673\n",
      "F1-Score의 micro 평균 :  0.817\n",
      "F1-Score의 weight 평균 :  0.8118\n",
      "---------------------------------------- \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\t5,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.8028\n",
      "F1-Score의 macro 평균 :  0.6526\n",
      "F1-Score의 micro 평균 :  0.8028\n",
      "F1-Score의 weight 평균 :  0.7977\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t15,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.8143\n",
      "F1-Score의 macro 평균 :  0.6682\n",
      "F1-Score의 micro 평균 :  0.8143\n",
      "F1-Score의 weight 평균 :  0.8092\n",
      "---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_train_test(normal_x_train, normal_y_train, normal_x_test, normal_y_test, LogisticRegression(C=10000, penalty='l2', max_iter=2000),'전체 단어장')\n",
    "model_train_test(word_5000_x_train, word_5000_y_train, word_5000_x_test, word_5000_y_test, LogisticRegression(C=10000, penalty='l2', max_iter=2000),'5,000 단어장')\n",
    "model_train_test(word_15000_x_train, word_15000_y_train, word_15000_x_test, word_15000_y_test, LogisticRegression(C=10000, penalty='l2', max_iter=2000),'15,000 단어장')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-purse",
   "metadata": {},
   "source": [
    "> 로지스틱 회귀의 정확도는 5,000 단어장(80.28%), 15,000 단어장(81.43%), 모든 단어장(81.7%)이다.<br>\n",
    "> 이전 나이브 베이즈 분류기 계열 모델에 비해 뉴스 카테고리를 분류하는 성능이 뛰어남을 확인할 수 있다.<br>\n",
    "> <br>\n",
    "> F1-Score의 weight는 5,000 단어장(0.7977), 15,000 단어장(0.8092), 모든 단어장(0.8118)의 결과를 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-reminder",
   "metadata": {},
   "source": [
    "### 3.2.4 선형 서포트 벡터 머신(Linear Support Vector Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-monitor",
   "metadata": {},
   "source": [
    "> 선형 서포트 벡터 머신은 대표적인 선형 분류 알고리듬으로, 이진 분류를 위한 모델이다.<br>\n",
    "> LSVM은 이진 분류 모델이나 1:N 방식으로 각 클래스를 다른 모든 클래스와 구분하도록 이진 분류 모델을 학습한다.<br>\n",
    "> 때문에, 클래스의 수만큼 이진 분류 모델이 만들어지며 예측할 때는 모든 이진 분류기를 활용하여 가장 높은 점수를 내는<br>\n",
    "> 분류기의 클래스를 예측값으로 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "small-california",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\t전체 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.7863\n",
      "F1-Score의 macro 평균 :  0.6416\n",
      "F1-Score의 micro 평균 :  0.7863\n",
      "F1-Score의 weight 평균 :  0.7822\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t5,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.7814\n",
      "F1-Score의 macro 평균 :  0.6179\n",
      "F1-Score의 micro 평균 :  0.7814\n",
      "F1-Score의 weight 평균 :  0.7765\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t15,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.7881\n",
      "F1-Score의 macro 평균 :  0.6492\n",
      "F1-Score의 micro 평균 :  0.7881\n",
      "F1-Score의 weight 평균 :  0.7832\n",
      "---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_train_test(normal_x_train, normal_y_train, normal_x_test, normal_y_test, LinearSVC(C=1000, penalty='l1', max_iter=2000, dual=False),'전체 단어장')\n",
    "model_train_test(word_5000_x_train, word_5000_y_train, word_5000_x_test, word_5000_y_test, LinearSVC(C=1000, penalty='l1', max_iter=2000, dual=False),'5,000 단어장')\n",
    "model_train_test(word_15000_x_train, word_15000_y_train, word_15000_x_test, word_15000_y_test, LinearSVC(C=1000, penalty='l1', max_iter=2000, dual=False),'15,000 단어장')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-bonus",
   "metadata": {},
   "source": [
    "> 선형 서포트 벡터 머신의 정확도는 5,000 단어장(77.38%), 15,000 단어장(78.58%), 모든 단어장(78.85%)이다.<br>\n",
    "> LSVM은 이전 CNB 모델처럼 가중치를 편향되지 않도록 분류하기에, 확률적으로 분류하는 로지스틱 회귀보다 낮은 성능을 보여주었다.<br>\n",
    "> 그러나 샘플 수가 많을 수록 정확도화 F1-Score weight가 향상됨을 확인할 수 있다.<br>\n",
    "> <br>\n",
    "> F1-Score의 weight는 5,000 단어장(0.77), 15,000 단어장(0.781), 모든 단어장(0.784)의 결과를 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-coordinator",
   "metadata": {},
   "source": [
    "### 3.2.5 결정 트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-ministry",
   "metadata": {},
   "source": [
    "> 결정 트리는 분류와 회귀 문제에 널리 사용하는 모델로, 각 분기점마다 이진 분류로 학습을 진행하는 모델이다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "organized-hudson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\t전체 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.6211\n",
      "F1-Score의 macro 평균 :  0.1545\n",
      "F1-Score의 micro 평균 :  0.6211\n",
      "F1-Score의 weight 평균 :  0.5769\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t5,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.618\n",
      "F1-Score의 macro 평균 :  0.1779\n",
      "F1-Score의 micro 평균 :  0.618\n",
      "F1-Score의 weight 평균 :  0.573\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t15,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.6193\n",
      "F1-Score의 macro 평균 :  0.1818\n",
      "F1-Score의 micro 평균 :  0.6193\n",
      "F1-Score의 weight 평균 :  0.5756\n",
      "---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_train_test(normal_x_train, normal_y_train, normal_x_test, normal_y_test, DecisionTreeClassifier(max_depth=10, random_state=0),'전체 단어장')\n",
    "model_train_test(word_5000_x_train, word_5000_y_train, word_5000_x_test, word_5000_y_test, DecisionTreeClassifier(max_depth=10, random_state=0),'5,000 단어장')\n",
    "model_train_test(word_15000_x_train, word_15000_y_train, word_15000_x_test, word_15000_y_test, DecisionTreeClassifier(max_depth=10, random_state=0),'15,000 단어장')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-surprise",
   "metadata": {},
   "source": [
    "> 결정 트리의 정확도는 5,000 단어장(61.8%), 15,000 단어장(61.9%), 모든 단어장(62.1%)이다.<br>\n",
    "> 결정 트리는 이진 분류과정에서, 불균형한 데이터의 특정 데이터에 편향되는 과적합 현상을 보여준다.<br>\n",
    "> <br>\n",
    "> F1-Score의 weight는 5,000 단어장(0.573), 15,000 단어장(0.575), 모든 단어장(0.576)의 결과를 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-immunology",
   "metadata": {},
   "source": [
    "### 3.2.6 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-dealing",
   "metadata": {},
   "source": [
    "> 랜덤 포레스트는 여러 머신러닝 모델을 연결하여 더 강력한 모델을 생성하는 앙상블 기법을 활용한 모델이다.<br>\n",
    "> 이전 결정 트리의 단점인 과적합을 활용하여 서로 다른 방향으로 과적합된 트리들을 조합함으로써 모델 전체에서의 과적합을 회피한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "present-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\t전체 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.6545\n",
      "F1-Score의 macro 평균 :  0.2795\n",
      "F1-Score의 micro 평균 :  0.6545\n",
      "F1-Score의 weight 평균 :  0.6226\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t5,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.7012\n",
      "F1-Score의 macro 평균 :  0.3596\n",
      "F1-Score의 micro 평균 :  0.7012\n",
      "F1-Score의 weight 평균 :  0.677\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t15,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.6714\n",
      "F1-Score의 macro 평균 :  0.2971\n",
      "F1-Score의 micro 평균 :  0.6714\n",
      "F1-Score의 weight 평균 :  0.6407\n",
      "---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_train_test(normal_x_train, normal_y_train, normal_x_test, normal_y_test, RandomForestClassifier(n_estimators=5, random_state=0),'전체 단어장')\n",
    "model_train_test(word_5000_x_train, word_5000_y_train, word_5000_x_test, word_5000_y_test, RandomForestClassifier(n_estimators=5, random_state=0),'5,000 단어장')\n",
    "model_train_test(word_15000_x_train, word_15000_y_train, word_15000_x_test, word_15000_y_test, RandomForestClassifier(n_estimators=5, random_state=0),'15,000 단어장')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-memory",
   "metadata": {},
   "source": [
    "> 랜덤 포레스트의 정확도는 5,000 단어장(70.1%), 15,000 단어장(67.1%), 모든 단어장(65.45%)이다.<br>\n",
    "> 랜덤 포레스트는 결정 트리보다 성능이 개선되었음을 확인할 수 있다.<br>\n",
    "> 그러나, 단어 수가 많아질 수록 연산할 노드가 많아지기에, 성능이 낮아지는 모습을 확인할 수 있다.<br>\n",
    "> <br>\n",
    "> F1-Score의 weight는 5,000 단어장(0.677), 15,000 단어장(0.640), 모든 단어장(0.622)의 결과를 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-chambers",
   "metadata": {},
   "source": [
    "### 3.2.7 그래디언트 부스팅 트리(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-resource",
   "metadata": {},
   "source": [
    "> 그래디언트 부스팅 트리는 여러 개의 결정 트리를 묶어 만드는 앙상블 모델이다.<br>\n",
    "> 랜덤 포레스트와 다르게 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 생성한다.<br>\n",
    "> 또한, 그래디언트 부스팅 트리는 일부 특성을 무시한다는 특징을 가진다.<br>\n",
    "> 때문에, 랜덤 포레스트를 먼저 사용해보고, 성능이나 예측 시간에서 만족스럽지 않은 경우에 그래디언트 부스팅 트리를 사용한다.<br>\n",
    "> 보통, 1 ~ 5 정도의 깊지 않은 트리를 사용하므로 메모리도 적게 사용하고 예측도 빠른 장점이 있다.<br>\n",
    "> 훈련이 오래 걸리고, 트리 기반 모델의 특성으로 인해서 희소한 고차원 데이터에 대해서는 잘 동작하지 않는다는 단점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "classical-crisis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\t전체 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.7703\n",
      "F1-Score의 macro 평균 :  0.5728\n",
      "F1-Score의 micro 평균 :  0.7703\n",
      "F1-Score의 weight 평균 :  0.7642\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t5,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.7676\n",
      "F1-Score의 macro 평균 :  0.5792\n",
      "F1-Score의 micro 평균 :  0.7676\n",
      "F1-Score의 weight 평균 :  0.7662\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t15,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.7707\n",
      "F1-Score의 macro 평균 :  0.5716\n",
      "F1-Score의 micro 평균 :  0.7707\n",
      "F1-Score의 weight 평균 :  0.7679\n",
      "---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_train_test(normal_x_train, normal_y_train, normal_x_test, normal_y_test, GradientBoostingClassifier(random_state=0),'전체 단어장')\n",
    "model_train_test(word_5000_x_train, word_5000_y_train, word_5000_x_test, word_5000_y_test, GradientBoostingClassifier(random_state=0),'5,000 단어장')\n",
    "model_train_test(word_15000_x_train, word_15000_y_train, word_15000_x_test, word_15000_y_test, GradientBoostingClassifier(random_state=0),'15,000 단어장')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-agent",
   "metadata": {},
   "source": [
    "> 그래디언트 부스팅 트리의 정확도는 5,000 단어장(76.76%), 15,000 단어장(77.07%), 모든 단어장(77.03%)이다.<br>\n",
    "> 그래디언트 부스팅 트리는 랜덤 포레스트보다 성능이 개선되었음을 확인할 수 있다.<br>\n",
    "> 이전 트리의 오차를 보완하는 방식 덕분에 단어 수에따른 성능의 차는 크지 않음을 확인할 수 있다.<br>\n",
    "> <br>\n",
    "> F1-Score의 weight는 5,000 단어장(0.766), 15,000 단어장(0.767), 모든 단어장(0.764)의 결과를 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-values",
   "metadata": {},
   "source": [
    "### 3.2.8 보팅(Voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-flexibility",
   "metadata": {},
   "source": [
    "> 보팅은 여러 앙상블 기법을 사용하면서, 투표를 통해 가장 좋은 결과를 도출하는 기법이다.<br>\n",
    "> 보팅은 하드 보팅과 소프트 보팅 두 가지로 나누어진다.<br>\n",
    "> 하드 보팅은 결과물에 대한 최종값을 투표해서 결정한다.<br>\n",
    "> 소프트 보팅은 최종 결과물이 나올 확률값을 모두 더해서 최종 결과물에 대한 각각의 확률을 구한 뒤 최종값을 도출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "moving-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\t전체 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.8161\n",
      "F1-Score의 macro 평균 :  0.6738\n",
      "F1-Score의 micro 평균 :  0.8161\n",
      "F1-Score의 weight 평균 :  0.8103\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t5,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.8094\n",
      "F1-Score의 macro 평균 :  0.6458\n",
      "F1-Score의 micro 평균 :  0.8094\n",
      "F1-Score의 weight 평균 :  0.8026\n",
      "---------------------------------------- \n",
      "\n",
      "----------------------------------------\n",
      "\t15,000 단어장\n",
      "----------------------------------------\n",
      "정확도 :  0.8157\n",
      "F1-Score의 macro 평균 :  0.667\n",
      "F1-Score의 micro 평균 :  0.8157\n",
      "F1-Score의 weight 평균 :  0.8086\n",
      "---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_voting_model():\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "            ('cb', ComplementNB())\n",
    "        ], voting='soft', n_jobs=-1\n",
    "    )\n",
    "    return voting_classifier\n",
    "\n",
    "model_train_test(normal_x_train, normal_y_train, normal_x_test, normal_y_test, get_voting_model(),'전체 단어장')\n",
    "model_train_test(word_5000_x_train, word_5000_y_train, word_5000_x_test, word_5000_y_test, get_voting_model(),'5,000 단어장')\n",
    "model_train_test(word_15000_x_train, word_15000_y_train, word_15000_x_test, word_15000_y_test, get_voting_model(),'15,000 단어장')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-dressing",
   "metadata": {},
   "source": [
    "> 보팅의 정확도는 5,000 단어장(80.9%), 15,000 단어장(81.5%), 모든 단어장(81.6%)이다.<br>\n",
    "> 보팅은 로지스틱 회귀와 비슷한 성능을 보이나, F1-Score가 로지스티 회귀보다 높은 모습을 보여준다.<br>\n",
    "> 이는, 불균형 데이터에서 보팅이 로지스틱 회귀 보다 좀 더 강하다는것을 확인할 수 있다.<br>\n",
    "> <br>\n",
    "> F1-Score의 weight는 5,000 단어장(0.8026), 15,000 단어장(0.8086), 모든 단어장(0.8103)의 결과를 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-settle",
   "metadata": {},
   "source": [
    "## 3.3 딥러닝 알고리듬 기반 모델 학습&테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-pharmacology",
   "metadata": {},
   "source": [
    "> 인공신경망 알고리듬을 활용하여 Reuters News 데이터를 학습 후 결과를 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-charger",
   "metadata": {},
   "source": [
    "### 3.3.1 Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-sterling",
   "metadata": {},
   "source": [
    "> 모델에 적용할 데이터를 사전에 Padding&One-Hot기법을 전처리하는 사용자 정의 함수를 구현한다.<br>\n",
    "> Reuters News의 본문 길이는 평균 145이므로, 약 2.5배의 범위로 400을 문장의 최대 길이로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "furnished-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_preprocessing(x_train, y_train, x_test, y_test, sentence_max_len):\n",
    "    x_train = pad_sequences(x_train, maxlen=sentence_max_len, padding=\"pre\")\n",
    "    x_test = pad_sequences(x_test, maxlen=sentence_max_len, padding=\"pre\")\n",
    "\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1996)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-happiness",
   "metadata": {},
   "source": [
    "> 위 사용자 정의 함수를 활용하여 LSTM에 모델에 사용할 각 후보군 데이터를 전처리하는 작업을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "welsh-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_n_x_train, pre_n_y_train, pre_n_x_val, pre_n_y_val, pre_n_x_test, pre_n_y_test = nlp_preprocessing(normal_x_train, normal_y_train, normal_x_test, normal_y_test, 400)\n",
    "pre_5000_x_train, pre_5000_y_train, pre_n_5000_val, pre_5000_y_val, pre_5000_x_test, pre_5000_y_test = nlp_preprocessing(word_5000_x_train, word_5000_y_train, word_5000_x_test, word_5000_y_test, 400)\n",
    "pre_15000_x_train, pre_15000_y_train, pre_15000_x_val, pre_15000_y_val, pre_15000_x_test, pre_15000_y_test = nlp_preprocessing(word_15000_x_train, word_15000_y_train, word_15000_x_test, word_15000_y_test, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-terror",
   "metadata": {},
   "source": [
    "### 3.3.2 model design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-brick",
   "metadata": {},
   "source": [
    "> 딥러닝 기반 알고리듬 중, 자연어 처리에 강점을 가진 LSTM 모델을 활용한다.<br>\n",
    "> 문장의 최대 길이(400)을 워드 벡터의 차원수로 설정하고, 46가지의 뉴스 주제를 분류하는 문제이므로 softmax 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "transparent-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(vocab_size):\n",
    "    word_vector_dim = 400\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    model.add(keras.layers.LSTM(128))\n",
    "    model.add(keras.layers.Dense(46, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', precision, recall, f1score])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-sleeping",
   "metadata": {},
   "source": [
    "> 모델의 예측 성능을 평가하기 위해, F1-Score를 성능 지료로 활용한다.<br>\n",
    "> Keras 2.0 부터는 사용자가 직접 F1-Score를 정의하여야 한다.<br>\n",
    "> 이에, [F1-Score code 블로그](https://blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221226716255)를 참고하여 F1-Score를 구성했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "warming-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_target, y_pred):\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1))\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1))\n",
    "\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-advocate",
   "metadata": {},
   "source": [
    "### 3.3.3 model train "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-consortium",
   "metadata": {},
   "source": [
    "> 모델 훈련 및 성능을 시각화하는 테스트 함수를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "provincial-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epoch, batch_size, x_train, y_train, x_val, y_val):   \n",
    "    history = model.fit(x_train, y_train, epochs=epoch, batch_size=batch_size, verbose=1,validation_data=(x_val, y_val))\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "maritime-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(history, trained_model, x_test, y_test):  \n",
    "    _loss, _acc, _precision, _recall, _f1score = trained_model.evaluate(x_test, y_test)\n",
    "    print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-binding",
   "metadata": {},
   "source": [
    "### 3.3.4 단어 5,000개를 사용한 LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-depth",
   "metadata": {},
   "source": [
    "> Vocabulary의 단어가 5,000개인 데이터를 활용한 LSTM model을 훈련 및 테스트하는 과정을 기술한다.<br>\n",
    "> 훈련 횟수는 15회이며, batch_size는 128로 설정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fleet-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 12s 176ms/step - loss: 2.9927 - accuracy: 0.3141 - precision: 0.0756 - recall: 0.0136 - f1score: 0.0219 - val_loss: 2.0600 - val_accuracy: 0.4942 - val_precision: 0.9315 - val_recall: 0.2696 - val_f1score: 0.4169\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 2.0415 - accuracy: 0.4828 - precision: 0.9316 - recall: 0.2747 - f1score: 0.4212 - val_loss: 1.8847 - val_accuracy: 0.5170 - val_precision: 0.8495 - val_recall: 0.3774 - val_f1score: 0.5215\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 1.7895 - accuracy: 0.5224 - precision: 0.8320 - recall: 0.4194 - f1score: 0.5536 - val_loss: 1.6820 - val_accuracy: 0.5821 - val_precision: 0.9021 - val_recall: 0.4904 - val_f1score: 0.6289\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 1.6704 - accuracy: 0.5704 - precision: 0.8718 - recall: 0.4845 - f1score: 0.6204 - val_loss: 1.6825 - val_accuracy: 0.5743 - val_precision: 0.8336 - val_recall: 0.4805 - val_f1score: 0.6086\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 1.5199 - accuracy: 0.6147 - precision: 0.8895 - recall: 0.5127 - f1score: 0.6495 - val_loss: 1.4646 - val_accuracy: 0.6528 - val_precision: 0.9096 - val_recall: 0.5100 - val_f1score: 0.6518\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 1.2555 - accuracy: 0.6989 - precision: 0.9193 - recall: 0.5870 - f1score: 0.7154 - val_loss: 1.3866 - val_accuracy: 0.6772 - val_precision: 0.8770 - val_recall: 0.5808 - val_f1score: 0.6958\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 1.0796 - accuracy: 0.7309 - precision: 0.9098 - recall: 0.6590 - f1score: 0.7638 - val_loss: 1.4100 - val_accuracy: 0.6661 - val_precision: 0.8626 - val_recall: 0.5537 - val_f1score: 0.6720\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 1.0012 - accuracy: 0.7524 - precision: 0.8954 - recall: 0.6667 - f1score: 0.7638 - val_loss: 1.3436 - val_accuracy: 0.6795 - val_precision: 0.8606 - val_recall: 0.5717 - val_f1score: 0.6774\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 0.8922 - accuracy: 0.7735 - precision: 0.9080 - recall: 0.6971 - f1score: 0.7882 - val_loss: 1.2655 - val_accuracy: 0.7168 - val_precision: 0.8608 - val_recall: 0.6314 - val_f1score: 0.7243\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 0.7161 - accuracy: 0.8224 - precision: 0.9198 - recall: 0.7465 - f1score: 0.8236 - val_loss: 1.2800 - val_accuracy: 0.7090 - val_precision: 0.8467 - val_recall: 0.6298 - val_f1score: 0.7181\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 0.5857 - accuracy: 0.8573 - precision: 0.9338 - recall: 0.7943 - f1score: 0.8581 - val_loss: 1.3054 - val_accuracy: 0.7229 - val_precision: 0.8254 - val_recall: 0.6475 - val_f1score: 0.7248\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 0.4739 - accuracy: 0.8890 - precision: 0.9470 - recall: 0.8180 - f1score: 0.8774 - val_loss: 1.3916 - val_accuracy: 0.7023 - val_precision: 0.8241 - val_recall: 0.6454 - val_f1score: 0.7189\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 0.4107 - accuracy: 0.9062 - precision: 0.9503 - recall: 0.8458 - f1score: 0.8946 - val_loss: 1.4138 - val_accuracy: 0.7001 - val_precision: 0.8208 - val_recall: 0.6310 - val_f1score: 0.7012\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 0.3395 - accuracy: 0.9234 - precision: 0.9599 - recall: 0.8738 - f1score: 0.9147 - val_loss: 1.4727 - val_accuracy: 0.7034 - val_precision: 0.8079 - val_recall: 0.6543 - val_f1score: 0.7221\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 9s 164ms/step - loss: 0.2884 - accuracy: 0.9356 - precision: 0.9591 - recall: 0.8993 - f1score: 0.9281 - val_loss: 1.4128 - val_accuracy: 0.7212 - val_precision: 0.7854 - val_recall: 0.6725 - val_f1score: 0.7244\n"
     ]
    }
   ],
   "source": [
    "vacab_5000_lstm_model = lstm_model(5000)\n",
    "vacab_5000_history, vacab_5000_trained_model = train_model(vacab_5000_lstm_model, 15, 128, pre_5000_x_train, pre_5000_y_train, pre_n_5000_val, pre_5000_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "union-canyon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 2s 26ms/step - loss: 1.5794 - accuracy: 0.7021 - precision: 0.7832 - recall: 0.6648 - f1score: 0.7177\n",
      "loss: 1.579, accuracy: 0.702, precision: 0.783, recall: 0.665, f1score: 0.718\n"
     ]
    }
   ],
   "source": [
    "test_model(vacab_5000_history,vacab_5000_trained_model, pre_5000_x_test, pre_5000_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-question",
   "metadata": {},
   "source": [
    "> Vocabulary의 단어가 5,000개인 LSTM Model을 테스트 결과는 아래와 같다.<br>\n",
    "> <br>\n",
    "> test_accuracy : 70.2%<br>\n",
    "> test_loss : 1.579<br>\n",
    "> test_F1-Score : 0.718<br>\n",
    "> test_Precision : 0.783<br>\n",
    "> test_Recall : 0.665<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-australia",
   "metadata": {},
   "source": [
    "### 3.3.5 단어 15,000개를 사용한 LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-turkish",
   "metadata": {},
   "source": [
    "> Vocabulary의 단어가 15,000개인 데이터를 활용한 LSTM model을 훈련 및 테스트하는 과정을 기술한다.<br>\n",
    "> 훈련 횟수는 15회이며, batch_size는 128로 설정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "moving-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 13s 200ms/step - loss: 3.0037 - accuracy: 0.3239 - precision: 0.1325 - recall: 0.0482 - f1score: 0.0612 - val_loss: 2.0063 - val_accuracy: 0.4942 - val_precision: 0.9498 - val_recall: 0.2685 - val_f1score: 0.4175\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 1.8874 - accuracy: 0.4914 - precision: 0.8901 - recall: 0.3552 - f1score: 0.4979 - val_loss: 1.7189 - val_accuracy: 0.5665 - val_precision: 0.8958 - val_recall: 0.4663 - val_f1score: 0.6122\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 1.6230 - accuracy: 0.5830 - precision: 0.8821 - recall: 0.4817 - f1score: 0.6214 - val_loss: 1.5999 - val_accuracy: 0.6093 - val_precision: 0.8714 - val_recall: 0.5343 - val_f1score: 0.6620\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 1.4323 - accuracy: 0.6306 - precision: 0.9019 - recall: 0.5361 - f1score: 0.6717 - val_loss: 1.4697 - val_accuracy: 0.6322 - val_precision: 0.8557 - val_recall: 0.5269 - val_f1score: 0.6510\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 1.1757 - accuracy: 0.6979 - precision: 0.9023 - recall: 0.5897 - f1score: 0.7123 - val_loss: 1.4072 - val_accuracy: 0.6489 - val_precision: 0.8587 - val_recall: 0.5253 - val_f1score: 0.6507\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 1.0150 - accuracy: 0.7466 - precision: 0.9294 - recall: 0.6509 - f1score: 0.7638 - val_loss: 1.2885 - val_accuracy: 0.6978 - val_precision: 0.8242 - val_recall: 0.5993 - val_f1score: 0.6919\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 0.7979 - accuracy: 0.8011 - precision: 0.9277 - recall: 0.7284 - f1score: 0.8157 - val_loss: 1.3325 - val_accuracy: 0.6962 - val_precision: 0.8187 - val_recall: 0.6311 - val_f1score: 0.7126\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 0.6513 - accuracy: 0.8400 - precision: 0.9382 - recall: 0.7658 - f1score: 0.8429 - val_loss: 1.3130 - val_accuracy: 0.7062 - val_precision: 0.8225 - val_recall: 0.6144 - val_f1score: 0.7013\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 0.5142 - accuracy: 0.8789 - precision: 0.9542 - recall: 0.8014 - f1score: 0.8709 - val_loss: 1.3709 - val_accuracy: 0.7078 - val_precision: 0.8064 - val_recall: 0.6582 - val_f1score: 0.7246\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.3961 - accuracy: 0.9071 - precision: 0.9548 - recall: 0.8406 - f1score: 0.8938 - val_loss: 1.4152 - val_accuracy: 0.7040 - val_precision: 0.7616 - val_recall: 0.6435 - val_f1score: 0.6969\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 0.3323 - accuracy: 0.9165 - precision: 0.9562 - recall: 0.8753 - f1score: 0.9138 - val_loss: 1.4244 - val_accuracy: 0.7001 - val_precision: 0.7499 - val_recall: 0.6467 - val_f1score: 0.6938\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 0.2775 - accuracy: 0.9302 - precision: 0.9567 - recall: 0.8935 - f1score: 0.9239 - val_loss: 1.4646 - val_accuracy: 0.7056 - val_precision: 0.7469 - val_recall: 0.6560 - val_f1score: 0.6983\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.2138 - accuracy: 0.9462 - precision: 0.9637 - recall: 0.9246 - f1score: 0.9436 - val_loss: 1.4686 - val_accuracy: 0.7067 - val_precision: 0.7562 - val_recall: 0.6451 - val_f1score: 0.6932\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.1869 - accuracy: 0.9542 - precision: 0.9644 - recall: 0.9360 - f1score: 0.9499 - val_loss: 1.6191 - val_accuracy: 0.6861 - val_precision: 0.7433 - val_recall: 0.6470 - val_f1score: 0.6916\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 0.1689 - accuracy: 0.9546 - precision: 0.9650 - recall: 0.9425 - f1score: 0.9536 - val_loss: 1.5393 - val_accuracy: 0.7095 - val_precision: 0.7317 - val_recall: 0.6550 - val_f1score: 0.6910\n"
     ]
    }
   ],
   "source": [
    "vacab_15000_lstm_model = lstm_model(15000)\n",
    "vacab_15000_history, vacab_15000_trained_model = train_model(vacab_15000_lstm_model, 15, 128, pre_15000_x_train, pre_15000_y_train, pre_15000_x_val, pre_15000_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cardiac-customer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 2s 26ms/step - loss: 1.7202 - accuracy: 0.6843 - precision: 0.7475 - recall: 0.6601 - f1score: 0.7000\n",
      "loss: 1.720, accuracy: 0.684, precision: 0.747, recall: 0.660, f1score: 0.700\n"
     ]
    }
   ],
   "source": [
    "test_model(vacab_15000_history,vacab_15000_trained_model, pre_15000_x_test, pre_15000_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-payment",
   "metadata": {},
   "source": [
    "> Vocabulary의 단어가 15,000개인 LSTM Model을 테스트 결과는 아래와 같다.<br>\n",
    "> <br>\n",
    "> test_accuracy : 68.4%<br>\n",
    "> test_loss : 1.720<br>\n",
    "> test_F1-Score : 0.7<br>\n",
    "> test_Precision : 0.747<br>\n",
    "> test_Recall : 0.66<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-hunter",
   "metadata": {},
   "source": [
    "### 3.3.6 모든 단어를 사용한 LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-public",
   "metadata": {},
   "source": [
    "> Vocabulary의 단어가 30,982개인 데이터를 활용한 LSTM model을 훈련 및 테스트하는 과정을 기술한다.<br>\n",
    "> 훈련 횟수는 15회이며, batch_size는 128로 설정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "respected-winner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 16s 249ms/step - loss: 2.9909 - accuracy: 0.3340 - precision: 0.0814 - recall: 0.0436 - f1score: 0.0512 - val_loss: 2.0796 - val_accuracy: 0.4613 - val_precision: 0.9064 - val_recall: 0.2769 - val_f1score: 0.4226\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 13s 234ms/step - loss: 1.9911 - accuracy: 0.4796 - precision: 0.8801 - recall: 0.3149 - f1score: 0.4565 - val_loss: 1.7666 - val_accuracy: 0.5659 - val_precision: 0.8150 - val_recall: 0.5145 - val_f1score: 0.6304\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 13s 235ms/step - loss: 1.6976 - accuracy: 0.5647 - precision: 0.8631 - recall: 0.4795 - f1score: 0.6109 - val_loss: 1.6679 - val_accuracy: 0.5815 - val_precision: 0.8265 - val_recall: 0.4722 - val_f1score: 0.6001\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 13s 232ms/step - loss: 1.3549 - accuracy: 0.6538 - precision: 0.9104 - recall: 0.5414 - f1score: 0.6779 - val_loss: 1.5015 - val_accuracy: 0.6188 - val_precision: 0.8290 - val_recall: 0.5118 - val_f1score: 0.6318\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 13s 233ms/step - loss: 1.0812 - accuracy: 0.7250 - precision: 0.9264 - recall: 0.6410 - f1score: 0.7566 - val_loss: 1.4331 - val_accuracy: 0.6583 - val_precision: 0.8155 - val_recall: 0.5618 - val_f1score: 0.6635\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 13s 234ms/step - loss: 0.8786 - accuracy: 0.7691 - precision: 0.9266 - recall: 0.7023 - f1score: 0.7979 - val_loss: 1.4193 - val_accuracy: 0.6611 - val_precision: 0.7996 - val_recall: 0.5639 - val_f1score: 0.6595\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 13s 234ms/step - loss: 0.6696 - accuracy: 0.8279 - precision: 0.9423 - recall: 0.7652 - f1score: 0.8441 - val_loss: 1.4642 - val_accuracy: 0.6694 - val_precision: 0.7914 - val_recall: 0.5779 - val_f1score: 0.6658\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 13s 234ms/step - loss: 0.5316 - accuracy: 0.8647 - precision: 0.9444 - recall: 0.7985 - f1score: 0.8651 - val_loss: 1.4399 - val_accuracy: 0.6845 - val_precision: 0.7773 - val_recall: 0.6092 - val_f1score: 0.6806\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 13s 235ms/step - loss: 0.4196 - accuracy: 0.8959 - precision: 0.9558 - recall: 0.8384 - f1score: 0.8929 - val_loss: 1.4978 - val_accuracy: 0.6973 - val_precision: 0.7515 - val_recall: 0.6264 - val_f1score: 0.6826\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 13s 236ms/step - loss: 0.2913 - accuracy: 0.9327 - precision: 0.9634 - recall: 0.8783 - f1score: 0.9188 - val_loss: 1.5093 - val_accuracy: 0.6978 - val_precision: 0.7574 - val_recall: 0.6248 - val_f1score: 0.6819\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 14s 248ms/step - loss: 0.2337 - accuracy: 0.9422 - precision: 0.9635 - recall: 0.9103 - f1score: 0.9361 - val_loss: 1.5630 - val_accuracy: 0.6917 - val_precision: 0.7427 - val_recall: 0.6352 - val_f1score: 0.6846\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 13s 233ms/step - loss: 0.2288 - accuracy: 0.9418 - precision: 0.9588 - recall: 0.9161 - f1score: 0.9369 - val_loss: 1.6103 - val_accuracy: 0.6945 - val_precision: 0.7289 - val_recall: 0.6425 - val_f1score: 0.6821\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 13s 235ms/step - loss: 0.1620 - accuracy: 0.9570 - precision: 0.9676 - recall: 0.9393 - f1score: 0.9532 - val_loss: 1.6074 - val_accuracy: 0.6939 - val_precision: 0.7503 - val_recall: 0.6394 - val_f1score: 0.6873\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 13s 235ms/step - loss: 0.1377 - accuracy: 0.9600 - precision: 0.9692 - recall: 0.9485 - f1score: 0.9587 - val_loss: 1.6363 - val_accuracy: 0.7062 - val_precision: 0.7505 - val_recall: 0.6550 - val_f1score: 0.6963\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 13s 235ms/step - loss: 0.1192 - accuracy: 0.9631 - precision: 0.9718 - recall: 0.9544 - f1score: 0.9630 - val_loss: 1.6482 - val_accuracy: 0.6917 - val_precision: 0.7547 - val_recall: 0.6538 - val_f1score: 0.6992\n"
     ]
    }
   ],
   "source": [
    "all_lstm_model = lstm_model(30982)\n",
    "history, trained_model = train_model(all_lstm_model, 15, 128, pre_n_x_train, pre_n_y_train, pre_n_x_val, pre_n_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "straight-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 2s 27ms/step - loss: 1.8123 - accuracy: 0.6687 - precision: 0.7385 - recall: 0.6408 - f1score: 0.6855\n",
      "loss: 1.812, accuracy: 0.669, precision: 0.739, recall: 0.641, f1score: 0.685\n"
     ]
    }
   ],
   "source": [
    "test_model(history,trained_model, pre_n_x_test, pre_n_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-gibraltar",
   "metadata": {},
   "source": [
    "> Vocabulary의 단어가 30,982개인 LSTM Model을 테스트 결과는 아래와 같다.<br>\n",
    "> <br>\n",
    "> test_accuracy : 66.9%<br>\n",
    "> test_loss : 1.812<br>\n",
    "> test_F1-Score : 0.685<br>\n",
    "> test_Precision : 0.739<br>\n",
    "> test_Recall : 0.641<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-stanley",
   "metadata": {},
   "source": [
    "# 연구 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-lloyd",
   "metadata": {},
   "source": [
    "> 본 연구의 목적인 '로이터 뉴스(Reuters News)' 데이터를 활용하여 머신러닝 알고리듬과 딥러닝 모델의 성능을 비교하고, 모델에서 사용하는 단어 수(vacabulary size)의 차이가 모델 성능에 영향을 미치는지 분석하는 실험을 진행한 결과는 아래의 표1, 표2와 같았다.<br>\n",
    "> <br>\n",
    "> 아래의 결과를 통해 Reuters News 데이터에 가장 적합한 모델은 보팅이라 생각한다.<br>\n",
    "> 보팅 머신러닝 알고리듬이 성능이 가장 유사한 로지스틱 회귀에 비해, 각 단어 수 차이에 따른 편차가 가장 적었기 때문이다.<br>\n",
    "> 이는 불균형 데이터에서 비교군 알고리듬에 비해 좀 더 강건한 장점이 있음을 의미한다.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "iraqi-database",
   "metadata": {},
   "source": [
    "<span style=\"text-align: center;\">\n",
    "    <b> 표1 | 머신러닝 알고리듬 기반 학습 결과 </b>\n",
    "</span>\n",
    "<br>\n",
    "\n",
    "|머신러닝 모델|accuracy(5,000, 15,000, ALL)|F1-Score weight(5,000, 15,000, ALL)|F1-Score micro(5,000, 15,000, ALL)|F1-Score macro(5,000, 15,000, ALL)|\n",
    "|---|------|---|---|---|\n",
    "|나이브 베이즈 분류기|63.31% / 67.32% / 59.97%|0.5498 / 0.6013 / 0.5046|0.6331 / 0.6732 / 0.5997|0.0853 / 0.1102 / 0.0677|\n",
    "|컴플리먼트 나이브 베이즈 분류기|59.97% / 67.32% / 63.31%|0.7459 / 0.7448 / 0.7347|0.7707 / 0.772 / 0.7649|0.482 / 0.4668 / 0.464|\n",
    "|로지스틱 회귀|80.28% / 81.43% / 81.7%|0.7977 / 0.8092 / 0.8118|0.8028 / 0.8143 / 0.817|0.6526 / 0.6682 / 0.673|\n",
    "|선형 서포트 벡터 머신| 77.38% / 78.58% / 78.85%| 0.7702 / 0.7814 / 0.784|0.7738 / 0.7858 / 0.7885|0.607 / 0.6201 / 0.6351|\n",
    "|결정 트리|61.8% / 61.93% / 62.11%|0.573 / 0.5756 / 0.5769|0.618 / 0.6193 / 0.6211|0.1779 / 0.1818 / 0.1545|\n",
    "|랜덤 포레스트|70.12% / 67.14% / 65.45%|0.677 / 0.6407 / 0.6226|0.7012 / 0.6714 / 0.6545|0.3596 / 0.2971 / 0.2795|\n",
    "|그래디언트 부스팅 트리|76.76% / 77.07% / 77.03%|0.7662 / 0.7679 / 0.7642|0.7703 / 0.7676 / 0.7707|0.5792 / 0.5716 / 0.5728|\n",
    "|보팅|80.94% / 81.57% / 81.61%|0.8026 / 0.8086 / 0.8103|0.8094 / 0.8157 / 0.8161|0.6458 / 0.667 / 0.6738|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-paste",
   "metadata": {},
   "source": [
    "<span style=\"text-align: center;\">\n",
    "    <b> 표2 | 인공신경망 알고리듬 LSTM 모델 기반 학습 결과 </b>\n",
    "</span>\n",
    "<br>\n",
    "\n",
    "|LSTM 모델|Test Accuracy|Test Loss|Test Precision|Test Recall|Test F1-Score|\n",
    "|---|------|---|---|---|---|\n",
    "|5,000 단어|70.2%|1.579|0.783|0.665|0.718|\n",
    "|15,000 단어|68.4%|1.72|0.747|0.66|0.7|\n",
    "|모든 단어|66.9%|1.812|0.739|0.641|0.685|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-movement",
   "metadata": {},
   "source": [
    "> 첫번째 연구 목적인 모델에서 사용하는 단어의 수(vacabulary size)가 모델 성능에 영향을 미치는가에 대한 연구 결과의 답은, 단어의 수가 모델 성능에 영향을 미친다는 것이다.<br>\n",
    "> <br>\n",
    "> 같은 모델을 사용했을때, 단어의 수에 따라 정확도, F1-Score (weight,micro, macro)의 성능이 유의미하게 차이가 나는 모습을 보여주었다.\n",
    "> 로지스텍 회귀, 선형 서포트 벡터 머신, 보팅 알고리듬과 같이 다중 분류에 특화된 머신러닝 알고리듬에서 좋은 성능을 보여주었다.\n",
    "> 나이브 베이즈 분류기, 컴플리먼트 나이브 베이즈 분류기, 결정 트리 알고리듬과 같이 이중 분류에 특화된 머신러닝 알고리듬에서는 낮은 성능을 보여주었다.\n",
    "> 컴플리먼트 나이브 베이즈 분류기, 그래디언트 부스팅 트리와 같이, 불균형 데이터에 보정을 하는 알고리듬은 F1-Score가 보정을 하지 않는 알고리듬보다 좋은 성능을 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-manual",
   "metadata": {},
   "source": [
    "> 두번째 연구 목적인 머신러닝 알고리듬과 LSTM 인공신경망 알고리듬의 성능을 비교했을 때, 머신러닝 알고리듬 비교군에따라 결과가 달랐다.<br>\n",
    "> 이중 분류 머신러닝 알고리듬에서는 인공신경망이 정확도, F1-Score 등 대부분의 기록에서 우위인 모습을 보여주었다.<br>\n",
    "> 그러나, 다중 분류 머신러닝에서는 인공신경망이 정확도, F1-Score 등 대부분의 기록에서 열세인 모습을 보여주었다.<br>\n",
    "> LSTM은 Reuters News 데이터의 80%를 구성하는 문장 길이가 400이내인 뉴스 본문에서는 70% 이상의 정확률(precision)을 보여주었다.<br>\n",
    "> 그러나, 400자 이상의 뉴스 본문을  Test 데이터셋을 사용할 시 상대적으로 낮은 정확률(Recall)을 보여주었다.<br>\n",
    "> LSTM모델 외에 다른 인공신경망에서 비교하는 연구가 더 필요할것같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
